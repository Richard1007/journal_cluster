{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a4a95c-b667-470b-b066-91d83d05633c",
   "metadata": {},
   "source": [
    "Laadt de survey valences in en scoor elke participant. We willen:\n",
    "* the number of positive/neutral/negative words each person gave\n",
    "* total number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec065b-60a2-48f0-bd83-c12b836fbb48",
   "metadata": {},
   "source": [
    "### 1. Load sentiment valences from survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1fa46a9-c293-43bf-96b9-e3ae4d4461d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepting is not in the valence list!\n",
      "likeable is not in the valence list!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# we build a dict where we have a word --> valence mapping\n",
    "valences     = pd.read_excel(\"data/word_valences.xlsm\",sheet_name=1)\n",
    "valences.edited = valences.edited.apply(lambda x : x.strip().lower())  # the 'edited' word for which we have a mapping\n",
    "bad1     = valences.edited.apply(lambda x  : x == \"please select negative\")\n",
    "valences = valences[~bad1]\n",
    "valences = dict(zip(valences.edited, valences['final valence']))\n",
    "\n",
    "# now we add misspellings etc to the dict\n",
    "words = pd.read_excel(\"data/word_valences.xlsm\",sheet_name=0)\n",
    "words.edited = words.edited.apply(lambda x : x.lower())\n",
    "for wordo, worde in zip(words.original,words.edited):\n",
    "    if(wordo not in valences):\n",
    "        if(worde in valences):\n",
    "            valences[wordo] = valences[worde]\n",
    "        else:\n",
    "            print(f\"{worde} is not in the valence list!\") #fixed hippy and preppy, yuppy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4da9d61b-eb08-4b76-a1d0-00f5f4e4de5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valences['happy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa5b29-faf9-422e-b718-0ca5538b6347",
   "metadata": {},
   "source": [
    "### 1. Load wordlist per participant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79eb42-18f8-4611-81b9-31b440228003",
   "metadata": {},
   "source": [
    "Code = first code-blocks of 1_Paper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1967694b-ae46-4ba0-9b72-ba59b8ff2f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring IP block and distribution channel\n",
      "Original data has 6145 rows.\n",
      "After deletion of rows with too few non-repetitive answers: 6145 rows\n",
      "Current cutoff is set to remove any count < 5\n",
      "Unrecognized word ratio (# nan / # cells): 14.55%\n",
      "After deletion of rows with too few (<=0) non-recognized answers: 6143 rows\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "from spacy.util import compile_infix_regex\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import enchant\n",
    "\n",
    "data_file_path   = \"./data/survey-all.csv\"                      # filepath\n",
    "numberbatch_path = \"counterfitting/numberbatch-counterfitted\"  # ConceptNet model\n",
    "nlp = spacy.load(numberbatch_path)\n",
    "\n",
    "\n",
    "# Avoid splitting of dashes\n",
    "def custom_tokenizer(nlp):\n",
    "    inf = list(nlp.Defaults.infixes)               # Default infixes\n",
    "    inf.remove(r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\")    # Remove the generic op between numbers or between a number and a -\n",
    "    inf = tuple(inf)                               # Convert inf to tuple\n",
    "    infixes = inf + tuple([r\"(?<=[0-9])[+*^](?=[0-9-])\", r\"(?<=[0-9])-(?=-)\"])  # Add the removed rule after subtracting (?<=[0-9])-(?=[0-9]) pattern\n",
    "    infixes = [x for x in infixes if '-|–|—|--|---|——|~' not in x] # Remove - between letters rule\n",
    "    infix_re = compile_infix_regex(infixes)\n",
    "\n",
    "    return Tokenizer(nlp.vocab, prefix_search=None,\n",
    "                                suffix_search=None,\n",
    "                                infix_finditer=None,\n",
    "                                token_match=None,\n",
    "                                rules=None)\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "from lib.addons_enric import censor_ips\n",
    "from lib.hard_launch import load_data, remove_anomaly, process_text, construct_participant_level_df\n",
    "\n",
    "# less for testing\n",
    "df  = load_data(data_file_path)\n",
    "df = remove_anomaly(df)\n",
    "df = censor_ips(df)\n",
    "df,invalid_word,val_word_cnt,df_corrected_words = process_text(df,nlp)\n",
    "df = construct_participant_level_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6766d539-e8a0-41bb-8ea9-320b418114ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.hard_launch import P1_lemma, P2_lemma\n",
    "\n",
    "# Keep ResponseId for Jeffrey to couple back later on\n",
    "# Keep other rows for sentiment\n",
    "#df_corrected_words\n",
    "\n",
    "from lib.hard_launch import P1_lemma, P2_lemma\n",
    "\n",
    "def combine(g):\n",
    "    return g.sum()\n",
    "\n",
    "df_words = df[P1_lemma+P2_lemma]\n",
    "df_words.index = df.ResponseId\n",
    "#df_words = df_words.sum()\n",
    "#df_words = df_words.apply(lambda x: np.unique(x))\n",
    "df_words = df_words.T.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2616e-42ac-4484-bb87-e2fe1e50b5a7",
   "metadata": {},
   "source": [
    "## 3. Add sentiment to response df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e98a5e2-58ae-4e82-b5fd-555d26699b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "accepting is unknown\n",
      "likeable is unknown\n",
      "accepting is unknown\n",
      "accepting is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "accepting is unknown\n",
      "accepting is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "accepting is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "accepting is unknown\n",
      "accepting is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n",
      "likeable is unknown\n"
     ]
    }
   ],
   "source": [
    "def score_words(words):\n",
    "    pos,neutral,neg,unknown,total = 0,0,0,0,len(words)\n",
    "    for word in words:\n",
    "        if(word not in valences):\n",
    "            unknown += 1\n",
    "            print(f'{word} is unknown')\n",
    "        else:\n",
    "            val = valences[word]\n",
    "            if(val =='positive'):\n",
    "                pos +=1\n",
    "            elif(val == 'neutral'):\n",
    "                neutral +=1\n",
    "            elif(val == 'negative'):\n",
    "                neg += 1\n",
    "            else:\n",
    "                print(\"something went wrong\",word,val)\n",
    "    return [pos,neutral,neg,unknown,total]\n",
    "\n",
    "tmp = df_words.apply(score_words)\n",
    "df_scored = pd.DataFrame(np.vstack(tmp.apply(lambda x : np.array(x)).values), index=tmp.index, columns=['positive','neutral','negative','unknown','total'])\n",
    "df_scored.to_csv('output/participant_valences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d8c05363-9083-4e77-92bd-bcc2461d9a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scored.unknown.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e7149834-9013-43e2-8b56-2b8280e68c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.hard_launch import P1_lemma, P2_lemma\n",
    "\n",
    "def combine(g):\n",
    "    return g.sum()\n",
    "\n",
    "df_words = df[[\"Source\"]+P1_lemma+P2_lemma].groupby(\"Source\").agg(combine).T\n",
    "df_words = df_words.sum()\n",
    "df_words = df_words.apply(lambda x: np.unique(x))\n",
    "\n",
    "srcs, vals = [],[]\n",
    "for i in df_words.index:\n",
    "    for w in df_words[i]:\n",
    "        srcs.append(i)\n",
    "        vals.append(w)\n",
    "\n",
    "df_words = pd.DataFrame(vals,srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8e136567-ec7c-4fcf-af13-e00869aff286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NLTK / SentiWordNet\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import numpy as np\n",
    "\n",
    "def score_sentiwordnet(word):\n",
    "    synset = list(swn.senti_synsets(word))\n",
    "    \n",
    "    if(len(list(synset)) > 0):\n",
    "        scores = list(synset)[0]\n",
    "        return [scores.neg_score(), scores.pos_score()]\n",
    "    return [0, 0]\n",
    "\n",
    "#### LIWC\n",
    "import liwc\n",
    "from collections import Counter\n",
    "\n",
    "parse, category_names = liwc.load_token_parser('./data/sentiment/LIWC2015_English.dic')\n",
    "def score_LIWC(word):\n",
    "    results = Counter(category for category in parse(word))\n",
    "    return [ \n",
    "        results['negemo (Negative Emotions)'],\n",
    "        results['posemo (Positive Emotions)']\n",
    "    ]\n",
    "\n",
    "#### General Inquiry\n",
    "#  http://www.wjh.harvard.edu/~inquirer/\n",
    "#  https://github.com/cran/SentimentAnalysis/blob/master/R/data.R\n",
    "GIpos = list(pd.read_csv('./data/sentiment/GIpos.csv')['x'])\n",
    "GIneg = list(pd.read_csv('./data/sentiment/GIneg.csv')['x'])\n",
    "def score_GI(word):\n",
    "    if(word.lower() in GIpos):\n",
    "        return [0,1]\n",
    "    if(word.lower() in GIneg):\n",
    "        return [1,0]\n",
    "    return [np.nan, np.nan]\n",
    "\n",
    "##### SenticNet\n",
    "from senticnet.senticnet import SenticNet\n",
    "sn = SenticNet()\n",
    "def score_senticnet(word):\n",
    "    try:\n",
    "        polarity_value = float(sn.polarity_value(word))\n",
    "    except:\n",
    "        return [np.nan, np.nan]\n",
    "    \n",
    "    if(polarity_value > 0):\n",
    "        return [0, polarity_value]\n",
    "    return [polarity_value,0]\n",
    "\n",
    "####### ANEW\n",
    "anew_list = pd.read_excel(\"data/sentiment/ANEW.xlsx\")\n",
    "anew_list = dict(zip(anew_list.word, anew_list.score))\n",
    "def score_anew(word):\n",
    "    if(word in anew_list):\n",
    "        return anew_list[word]\n",
    "    return np.nan\n",
    "\n",
    "###### Evaluative Lexicon\n",
    "EL_list = pd.read_csv(\"data/sentiment/EvaluativeLexicon20.csv\")\n",
    "EL_list = dict(zip(EL_list.Word, EL_list.Valence))\n",
    "def score_el(word):\n",
    "    if(word in EL_list):\n",
    "        return EL_list[word]\n",
    "    return np.nan\n",
    "\n",
    "def all_scores(word):\n",
    "    word = word.lower()\n",
    "    return np.r_[\n",
    "        score_LIWC(word),\n",
    "        score_sentiwordnet(word),\n",
    "        score_GI(word),\n",
    "        score_senticnet(word),\n",
    "        score_anew(word),\n",
    "        score_el(word)\n",
    "    ]\n",
    "sent_vars = [\"LIWC_neg\",\"LIWC_pos\",\"SentiWordNet_neg\",\"SentiWordNet_pos\",\"GI_neg\",\"GI_pos\",\"SenticNet_neg\",\"SenticNet_pos\",\"ANEW\",\"EL\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89321b46-1ccb-4442-8815-ca397b664e95",
   "metadata": {},
   "source": [
    "Apply score functions to the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "62a47f71-58ec-43ea-a91a-9682ee6d37cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words  = [ w[0] for w in df_words.values ]\n",
    "scores = [ all_scores(w) for w in words]\n",
    "df_scored = pd.DataFrame(scores, columns=sent_vars, index=words)\n",
    "df_scored[\"Source\"] = df_words.index\n",
    "df_scored.to_csv(\"output/corpus_sentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "18abf17d-1a9c-4085-8faa-26bac2f1c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.unique(words)).to_csv(\"output/unique_words.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e9442-7bb8-4177-aa04-e6ee697b4a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
